{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "from scipy.interpolate import interp1d\r\n",
    "from scipy.stats import norm\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline\r\n",
    "import price_data as price\r\n",
    "import statistics\r\n",
    "import time\r\n",
    "from datetime import date\r\n",
    "import os\r\n",
    "from gql import gql, Client\r\n",
    "from gql.transport.aiohttp import AIOHTTPTransport\r\n",
    "\r\n",
    "# Select your transport with a defined url endpoint\r\n",
    "transport = AIOHTTPTransport(url=\"https://saturn.hasura.app/v1/graphql\", headers={'x-hasura-admin-secret': 'Rc07SJt4ryC6RyNXDKFRAtFmRkGBbT8Ez3SdaEYsHQoHemCldvs52Kc803oK8X62'})\r\n",
    "\r\n",
    "# Create a GraphQL client using the defined transport\r\n",
    "client = Client(transport=transport, fetch_schema_from_transport=True)\r\n",
    "\r\n",
    "async def get_stored_data(symbol,timeframe):\r\n",
    "    # Provide a GraphQL query\r\n",
    "    split_symbol=symbol.split('/')\r\n",
    "    base_currency=split_symbol[0]\r\n",
    "    quote_currency=split_symbol[1]\r\n",
    "    table=base_currency+quote_currency+'_'+timeframe\r\n",
    "    if table=='BTCUSD_1d':\r\n",
    "        query = gql(\r\n",
    "            \"\"\"\r\n",
    "            query MyQuery {\r\n",
    "                BTCUSD_1d {\r\n",
    "                    unix\r\n",
    "                    close\r\n",
    "                    high\r\n",
    "                    low\r\n",
    "                    open\r\n",
    "                }\r\n",
    "            }\r\n",
    "        \"\"\"\r\n",
    "        )\r\n",
    "    elif table=='ETHUSD_1d':\r\n",
    "        query = gql(\r\n",
    "            \"\"\"\r\n",
    "            query MyQuery {\r\n",
    "                ETHUSD_1d {\r\n",
    "                    unix\r\n",
    "                    close\r\n",
    "                    high\r\n",
    "                    low\r\n",
    "                    open\r\n",
    "                }\r\n",
    "            }\r\n",
    "        \"\"\"\r\n",
    "        )\r\n",
    "    elif table=='ETHBTC_1d':\r\n",
    "        query = gql(\r\n",
    "            \"\"\"\r\n",
    "            query MyQuery {\r\n",
    "                ETHBTC_1d {\r\n",
    "                    unix\r\n",
    "                    close\r\n",
    "                    high\r\n",
    "                    low\r\n",
    "                    open\r\n",
    "                }\r\n",
    "            }\r\n",
    "        \"\"\"\r\n",
    "        )\r\n",
    "    else:\r\n",
    "        return 'no such table'\r\n",
    "\r\n",
    "    # Execute the query on the transport\r\n",
    "    result = await client.execute_async(query)\r\n",
    "    candles=result[table]\r\n",
    "    df=pd.DataFrame({},columns=['unix','close','high','low','open'])\r\n",
    "    for candle in candles:\r\n",
    "        df=df.append(candle,ignore_index=True)\r\n",
    "\r\n",
    "    return df.sort_values(by=['unix'], ignore_index=True)\r\n",
    "\r\n",
    "    return result\r\n",
    "\r\n",
    "def find_start(timestamps):\r\n",
    "    start_found=False\r\n",
    "    timestamps=list(map(lambda x:x[0]/1000,timestamps))\r\n",
    "    index=len(timestamps)-1\r\n",
    "    while not(start_found):\r\n",
    "        print(timestamps[index])\r\n",
    "        day=date.fromtimestamp(timestamps[index]).weekday()\r\n",
    "        if day==0:\r\n",
    "            start_found=True\r\n",
    "        else:   \r\n",
    "            index=index-1\r\n",
    "    return index\r\n",
    "\r\n",
    "def read_data(filename):\r\n",
    "    raw=pd.read_csv('data/'+filename)\r\n",
    "    timestamps=raw['unix']\r\n",
    "    for i in range(len(timestamps)):\r\n",
    "        if np.log10(timestamps.iloc[i])<12:\r\n",
    "            raw.loc[i,'unix']=timestamps[i]*1000\r\n",
    "    return raw.sort_values(by=['unix'], ignore_index=True)\r\n",
    "\r\n",
    "btc_price_data= await get_stored_data('BTC/USD','1d')\r\n",
    "btc_price_data"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "weekly_candles=price.get_price_data('1w',data=btc_price_data)\r\n",
    "weekly_candles"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def update_csv(symbol,timeframe):\r\n",
    "    \r\n",
    "    split_symbol=symbol.split('/')\r\n",
    "    base_currency=split_symbol[0]\r\n",
    "    quote_currency=split_symbol[1]\r\n",
    "    filename=base_currency+quote_currency+'_'+timeframe+'.csv'\r\n",
    "    old_data=pd.read_csv('data/'+filename)\r\n",
    "    print(old_data)\r\n",
    "    max_timestamp=old_data['unix'].max()\r\n",
    "\r\n",
    "    latest_price_data=price.get_price_data(symbol,interval,since=max_timestamp)\r\n",
    "\r\n",
    "    new_data=latest_price_data[latest_price_data['unix']>=max_timestamp]\r\n",
    "    old_data.drop(old_data['unix'].idxmax())\r\n",
    "\r\n",
    "    new_file=old_data.append(new_data,ignore_index=True)\r\n",
    "\r\n",
    "    print(new_file)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_sma(data,window, close=True):\r\n",
    "     #using daily for now\r\n",
    "    timestamps=data['unix'][window-1:]\r\n",
    "    if close:\r\n",
    "        sma=data.rolling(window).mean()['close'].dropna()\r\n",
    "    else:\r\n",
    "        sma=data.rolling(window).mean()['open'].dropna()\r\n",
    "    return pd.DataFrame({'unix': timestamps,'value':sma})\r\n",
    "\r\n",
    "    # return pd.DataFrame({'unix': list(map(lambda x: x[0], sma)),'value':list(map(lambda x: x[1], sma))})\r\n",
    "\r\n",
    "def get_ema(data,window, close=False):\r\n",
    "    timestamps=data['unix'][window:]\r\n",
    "    if close:\r\n",
    "        ema=data.ewm(span=window,min_periods=window+1, adjust=False).mean()['close'].dropna()\r\n",
    "    else:\r\n",
    "        ema=data.ewm(span=window,min_periods=window+1, adjust=False).mean()['open'].dropna()\r\n",
    "    return pd.DataFrame({'unix': timestamps,'value':ema})\r\n",
    "\r\n",
    "def get_dema(data,window,close=False):\r\n",
    "    ema=get_ema(data,window)\r\n",
    "    ema=ema.rename(columns={'value':'open'})\r\n",
    "    smoothed_ema=get_ema(ema,window)\r\n",
    "    #making both vectors the same length\r\n",
    "    start=np.min(smoothed_ema.index.values)\r\n",
    "    ema=ema.loc[start:]\r\n",
    "    timestamps=ema['unix'].values\r\n",
    "    ema=ema['open'].values\r\n",
    "    smoothed_ema=smoothed_ema['value'].values\r\n",
    "    dema=2*ema-smoothed_ema\r\n",
    "    return pd.DataFrame({'unix': timestamps,'value':dema})\r\n",
    "\r\n",
    "def risk_indicator(fast,slow):\r\n",
    "    min_timestamp=max(fast['unix'].min(),slow['unix'].min())\r\n",
    "\r\n",
    "    trimmed_fast=fast.loc[fast['unix']>=min_timestamp]\r\n",
    "    slow=slow.loc[slow['unix']>=min_timestamp]\r\n",
    "    if len(trimmed_fast)>len(slow): \r\n",
    "        #different values, ie using a daily for fast and weekly for slow\r\n",
    "        if (slow['unix'].max()<trimmed_fast['unix'].max()):\r\n",
    "            print('true')\r\n",
    "            #add another value to the slow moving avarage to facilitate interpolation\r\n",
    "            slow=slow.append({'unix': trimmed_fast['unix'].max(), 'value':slow.iloc[-1]['value']},ignore_index=True)\r\n",
    "        f=interp1d(slow['unix'],slow['value'])\r\n",
    "        slow_interpolated=f(trimmed_fast['unix'])\r\n",
    "        slow=pd.DataFrame({'unix':trimmed_fast['unix'],'value':slow_interpolated})\r\n",
    "\r\n",
    "    if ('close' in fast.columns.values.tolist()):\r\n",
    "        #using price\r\n",
    "        risk_metric=np.divide(trimmed_fast['close'],slow['value'])\r\n",
    "    else:\r\n",
    "        #using moving average\r\n",
    "        risk_metric=np.divide(trimmed_fast['value'],slow['value'])\r\n",
    "\r\n",
    "    mean=np.mean(risk_metric)\r\n",
    "    sigma=np.std(risk_metric)\r\n",
    "    normalised=(risk_metric-mean)/sigma\r\n",
    "    risk=norm.cdf(normalised)\r\n",
    "    return pd.DataFrame({'unix':trimmed_fast['unix'],'value':risk})\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fast=get_sma(btc_price_data,10)\r\n",
    "fast_ema=get_ema(btc_price_data,50)\r\n",
    "slow=get_sma(weekly_candles,50)"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "month_dictionary={\r\n",
    "    'Jan':1,\r\n",
    "    'Feb':2,\r\n",
    "    'Mar':3,\r\n",
    "    'Apr':4,\r\n",
    "    'May':5,\r\n",
    "    'Jun':6,\r\n",
    "    'Jul':7,\r\n",
    "    'Aug':8,\r\n",
    "    'Sep':9,\r\n",
    "    'Oct':10,\r\n",
    "    'Nov':11,\r\n",
    "    'Dec':12,\r\n",
    "}\r\n",
    "\r\n",
    "def parse_data(datestring):\r\n",
    "    string=datestring.split('-')\r\n",
    "    month=month_dictionary[string[0]]\r\n",
    "    day=int(string[1])\r\n",
    "    year=int(string[2])\r\n",
    "    d=date(year,month,day)\r\n",
    "\r\n",
    "    return int(time.mktime(d.timetuple()))\r\n",
    "    \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def process_coincodex_csv(filename):\r\n",
    "\r\n",
    "    raw_data=pd.read_csv('data/'+filename)\r\n",
    "    vectorised_parsing=np.vectorize(parse_data)\r\n",
    "    timestamps=vectorised_parsing(raw_data['Date'].values)\r\n",
    "    df=raw_data\r\n",
    "\r\n",
    "    df['unix']=timestamps\r\n",
    "    df.columns = ['date','open','high','low','close','volume','market cap','unix']\r\n",
    "    df.sort_values(by='unix', ignore_index=True, inplace=True)\r\n",
    "    df.to_csv('data/'+filename+'_updated')\r\n",
    "\r\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def find_intercepts(fast,slow): #each line is a dataframe with time stamp and value, assuming both have same length\r\n",
    "    #starting state\r\n",
    "    min_timestamp=max(fast['unix'].min(),slow['unix'].min())\r\n",
    "\r\n",
    "    fast=fast.loc[fast['unix']>=min_timestamp]\r\n",
    "    slow=slow.loc[slow['unix']>=min_timestamp]\r\n",
    "\r\n",
    "    if len(fast) != len(slow):\r\n",
    "        f=interp1d(slow['unix'],slow['value'])\r\n",
    "        slow_interpolated=f(fast['unix'])\r\n",
    "        slow=pd.DataFrame({'unix':fast['unix'],'value':slow_interpolated})\r\n",
    "\r\n",
    "    timestamps=fast['unix'].values\r\n",
    "    line1=fast['value'].values\r\n",
    "    line2=slow['value'].values\r\n",
    "\r\n",
    "    line1_above_line2=line1[0]>line2[0] #state\r\n",
    "    cross_above=[]\r\n",
    "    cross_below=[]\r\n",
    "    for i in range(len(line1)):\r\n",
    "        if line1_above_line2 and line1[i]<line2[i]:\r\n",
    "            cross_below.append(timestamps[i])\r\n",
    "        elif not(line1_above_line2) and line1[i]>line2[i]:\r\n",
    "            cross_above.append(timestamps[i])\r\n",
    "        \r\n",
    "        line1_above_line2 = line1[i]>line2[i]\r\n",
    "\r\n",
    "    return {'cross_above': cross_above,'cross_below': cross_below }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "eth=await get_stored_data('ETH/USD','1d')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def ma_channel(data, window):\r\n",
    "    timestamps=data['unix']\r\n",
    "    sma=data.rolling(window).mean()\r\n",
    "    sma['unix']=timestamps\r\n",
    "    sma.dropna(inplace=True)    \r\n",
    "\r\n",
    "    return pd.DataFrame({'unix':sma['unix'],'high':sma['high'], 'low':sma['low'], 'value':sma['open']})\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def backtest_ma_channel(data,period, slow_ma_gradient):\r\n",
    "    print('Datapoints: ',len(data))\r\n",
    "    equity=1\r\n",
    "\r\n",
    "    channel=ma_channel(data,period)\r\n",
    "    start=channel['unix'].min()\r\n",
    "    trimmed_data=channel.loc[channel['unix']>=start]\r\n",
    "\r\n",
    "    state='neutral'\r\n",
    "    equity_record=[]\r\n",
    "    longs=[]\r\n",
    "    shorts=[]\r\n",
    "    outcome=[]\r\n",
    "    profit=[]\r\n",
    "    for i in range(len(channel)):\r\n",
    "        upper_bound=channel.iloc[i]['high']\r\n",
    "        lower_bound=channel.iloc[i]['low']\r\n",
    "        time=channel.iloc[i]['unix']\r\n",
    "        \r\n",
    "        day=max(list(filter(lambda x: x <= time, slow_ma_gradient.index.values)))\r\n",
    "        gradient=slow_ma_gradient.loc[day]\r\n",
    "        five_opens=data.loc[data['unix']<=time].tail(n=5)['open'].values # uses opens now as opens are confirmed\r\n",
    "        current=five_opens[-1]\r\n",
    "        uptrend=gradient>0\r\n",
    "        \r\n",
    "        if all(opens>upper_bound for opens in five_opens) and state != 'long' and uptrend.all():\r\n",
    "            #remember to calculate profit if flipping from short\r\n",
    "            if state=='short':\r\n",
    "                outcome.append(current<entry)\r\n",
    "                profit.append(1-(current/entry))\r\n",
    "                equity=equity*(1+(1-(current/entry)))\r\n",
    "                # equity=(entry*trade_amount-current*trade_amount)+equity\r\n",
    "            state='long'\r\n",
    "            entry=current\r\n",
    "            longs.append(time)\r\n",
    "        elif all(opens<lower_bound for opens in five_opens) and state != 'short' and not(uptrend.all()):\r\n",
    "            if state=='long':\r\n",
    "                outcome.append(current>entry)\r\n",
    "                profit.append(current/entry -1)\r\n",
    "                equity=equity*(1+(current/entry -1))\r\n",
    "            entry=current\r\n",
    "            # trade_amount=equity*entry\r\n",
    "            state='short'\r\n",
    "            shorts.append(time)\r\n",
    "            #print(state+' from $'+str(current))\r\n",
    "        if equity < 0:\r\n",
    "            equity=0\r\n",
    "            print('went broke')\r\n",
    "            break\r\n",
    "    \r\n",
    "    return longs,shorts,np.array(outcome), np.array(profit), equity\r\n",
    "\r\n",
    "def get_gradient(ma):\r\n",
    "    \r\n",
    "    return pd.Series(\r\n",
    "        index=ma['unix'].values,\r\n",
    "        data=np.gradient(ma['value'])\r\n",
    "    )\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "# equity_curve=backtest_ma_channel(eth_hourly,20)[2]\r\n"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "eth=read_data('Bitstamp_ETHUSD_d.csv')\r\n",
    "eth_hourly=read_data('Bitstamp_ETHUSD_1h.csv')\r\n",
    "# eth=price.get_price_data('1d', symbol='ETH/USD')\r\n",
    "# eth_hourly=price.get_price_data('1h', symbol='ETH/USD')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "\r\n",
    "results=[]\r\n",
    "for ema_period in range(1,8):\r\n",
    "    print('ema=', ema_period)\r\n",
    "    ema=get_ema(eth,ema_period, False)\r\n",
    "    ema_gradient=get_gradient(ema)\r\n",
    "    dema=get_dema(eth_hourly,ema_period,False)\r\n",
    "    dema_gradient=get_gradient(dema)\r\n",
    "    for ma_channel_period in range(24,30):\r\n",
    "        print('ma=', ma_channel_period)\r\n",
    "        longs, shorts, outcome, profit, final_equity=backtest_ma_channel(eth_hourly, ma_channel_period,ema_gradient)\r\n",
    "        result=[ema_period,ma_channel_period,np.sum(outcome)/np.size(outcome),profit, final_equity]\r\n",
    "        print('testing with dema now:')\r\n",
    "        longs, shorts, outcome, profit, final_equity=backtest_ma_channel(eth_hourly, ma_channel_period,dema_gradient)\r\n",
    "        result.extend([ema_period,np.sum(outcome)/np.size(outcome),profit, final_equity])\r\n",
    "        results.append(result)\r\n",
    "        "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ema= 1\n",
      "ma= 24\n",
      "Datapoints:  27787\n",
      "Datapoints:  27787\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11824/1859886523.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mlongs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshorts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutcome\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprofit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_equity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbacktest_ma_channel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meth_hourly\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma_channel_period\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mema_gradient\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mresult\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mema_period\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mma_channel_period\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutcome\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutcome\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprofit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_equity\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mlongs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshorts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutcome\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprofit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_equity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbacktest_ma_channel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meth_hourly\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma_channel_period\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdema_gradient\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mema_period\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutcome\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutcome\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprofit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_equity\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11824/1513031579.py\u001b[0m in \u001b[0;36mbacktest_ma_channel\u001b[1;34m(data, period, slow_ma_gradient)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mtime\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchannel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'unix'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mday\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslow_ma_gradient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mgradient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mslow_ma_gradient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mfive_opens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'unix'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'open'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;31m# uses opens now as opens are confirmed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11824/1513031579.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mtime\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchannel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'unix'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mday\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslow_ma_gradient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mgradient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mslow_ma_gradient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mfive_opens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'unix'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'open'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;31m# uses opens now as opens are confirmed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "results_df=pd.DataFrame(np.array(results),columns=['ema','channel','success_rate','profit', 'final_equity', 'dema','success_rate','profit', 'final_equity'])\r\n",
    "results_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "filtered=results_df[results_df['final_equity']>30000]\r\n",
    "profit_arrays=filtered['profit'].values\r\n",
    "win_array=[]\r\n",
    "loss_array=[]\r\n",
    "max_profit=[]\r\n",
    "max_drawdown=[]\r\n",
    "number_of_trades=[]\r\n",
    "for i in range(len(profit_arrays)):\r\n",
    "    array=profit_arrays[i]\r\n",
    "    win_filter=array>0\r\n",
    "    wins=array[win_filter]\r\n",
    "    loss_filter=array<0\r\n",
    "    loss=array[loss_filter]\r\n",
    "    win_array.append(wins)\r\n",
    "    max_profit.append(max(wins))\r\n",
    "    loss_array.append(loss)\r\n",
    "    max_drawdown.append(min(loss))\r\n",
    "    number_of_trades.append(len(array))\r\n",
    "    assert len(wins)/(len(array))==filtered.iloc[i]['success_rate']\r\n",
    "filtered['wins']=win_array\r\n",
    "filtered['losses']=loss_array\r\n",
    "filtered['max_profit']=max_profit\r\n",
    "filtered['max_drawdown']=max_drawdown\r\n",
    "filtered['number_of_trades']=number_of_trades\r\n",
    "filtered"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "best_result=filtered.iloc[0]\r\n",
    "wins=pd.Series(best_result['wins'])\r\n",
    "loss=pd.Series(best_result['losses'])\r\n",
    "print(wins.describe(),loss.describe())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ema=get_ema(eth,2, False)\r\n",
    "gradient=get_gradient(ema)\r\n",
    "channel=ma_channel(eth_hourly,26)\r\n",
    "longs, shorts, outcome, profit, final_equity=backtest_ma_channel(eth_hourly, 26,gradient)\r\n",
    "print('done')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#testing on recent data\r\n",
    "recent_eth_hourly=price.get_price_data('1h', symbol='ETH/USD')\r\n",
    "recent_eth_daily=price.get_price_data('1d', symbol='ETH/USD')\r\n",
    "\r\n",
    "results2=[]\r\n",
    "# for ema_period in range(10,50):\r\n",
    "#     print('ema=', ema_period)\r\n",
    "ema=get_ema(recent_eth_daily,2, False)\r\n",
    "gradient=get_gradient(ema)\r\n",
    "channel=ma_channel(recent_eth_hourly,26)\r\n",
    "#     for ma_channel_period in range(10,50):\r\n",
    "#         print('ma=', ma_channel_period)\r\n",
    "longs, shorts, outcome, profit, final_equity=backtest_ma_channel(recent_eth_hourly, 26,gradient)\r\n",
    "#         if len(outcome)==0:\r\n",
    "#             print('skipping')\r\n",
    "#             break\r\n",
    "#         print(np.sum(outcome)/len(outcome))\r\n",
    "#         print(np.mean(profit))\r\n",
    "#         print(final_equity)\r\n",
    "\r\n",
    "# results2.append([ema_period,ma_channel_period,np.sum(outcome)/np.size(outcome),profit, final_equity])\r\n",
    "# results_df2=pd.DataFrame(np.array(results),columns=['ema','channel','success_rate','profit', 'final_equity'])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.sum(outcome)/np.size(outcome),profit, final_equity"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(np.sum(outcome)/len(outcome))\r\n",
    "np.mean(profit)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ethbtc=process_coincodex_csv('ETHBTC_d.csv')\r\n",
    "risk=risk_indicator(ethbtc,get_sma(ethbtc,350))\r\n",
    "fig1,ax1 = plt.subplots()\r\n",
    "ax1.plot(risk['unix'],risk['value'])"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "976a7013ae9b6375dd3b6fd8012ded46dcef65ed674c8a499dd2f473ac3f0d66"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}